{
    "metadata": {
        "kernelspec": {
            "name": "scala-spark21", 
            "display_name": "Scala 2.11 with Spark 2.1", 
            "language": "scala"
        }, 
        "language_info": {
            "codemirror_mode": "text/x-scala", 
            "version": "2.11.8", 
            "file_extension": ".scala", 
            "name": "scala", 
            "mimetype": "text/x-scala", 
            "pygments_lexer": "scala"
        }
    }, 
    "cells": [
        {
            "metadata": {}, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": 1, 
            "source": "//https://dataplatform.ibm.com/exchange/public/entry/view/38feb8757afdb2c3c28a0dda489c2279\n\nval link_telco = \"https://raw.githubusercontent.com/AlgorithmDemo/SampleData/master/telco.csv\"\n\nimport sys.process._\nimport java.net.URL\nimport java.io.File\nnew URL(link_telco) #> new File(\"telco.csv\") !!\n\nval link_telco_Feb = \"https://raw.githubusercontent.com/AlgorithmDemo/SampleData/master/telco_Feb.csv\"\n\nimport sys.process._\nimport java.net.URL\nimport java.io.File\nnew URL(link_telco_Feb) #> new File(\"telco_Feb.csv\") !!"
        }, 
        {
            "metadata": {}, 
            "cell_type": "code", 
            "outputs": [
                {
                    "metadata": {}, 
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "Waiting for a Spark session to start..."
                    }
                }, 
                {
                    "text": "+------+------+---+-------+-------+------+---+------+------+------+------+--------+-----+--------+--------+-------+-------+--------+-------+-------+-------+-------+--------+-------+-------+--------+-----+-----+--------+------+--------+-------+------+-----+----------------+-------+-------+----------------+-------+----------------+-------+-----+\n|region|tenure|age|marital|address|income| ed|employ|retire|gender|reside|tollfree|equip|callcard|wireless|longmon|tollmon|equipmon|cardmon|wiremon|longten|tollten|equipten|cardten|wireten|multline|voice|pager|internet|callid|callwait|forward|confer|ebill|         loglong|logtoll|logequi|         logcard|logwire|           lninc|custcat|churn|\n+------+------+---+-------+-------+------+---+------+------+------+------+--------+-----+--------+--------+-------+-------+--------+-------+-------+-------+-------+--------+-------+-------+--------+-----+-----+--------+------+--------+-------+------+-----+----------------+-------+-------+----------------+-------+----------------+-------+-----+\n|     2|    13| 44|      1|      9|    64|  4|     5|     0|     0|     2|       0|    0|       1|       0|    3.7|    0.0|     0.0|    7.5|    0.0|  37.45|    0.0|     0.0|  110.0|    0.0|       0|    0|    0|       0|     0|       0|      1|     0|    0|1.30833281965018|       |       |2.01490302054226|       |4.15888308335967|      1|    1|\n+------+------+---+-------+-------+------+---+------+------+------+------+--------+-----+--------+--------+-------+-------+--------+-------+-------+-------+-------+--------+-------+-------+--------+-----+-----+--------+------+--------+-------+------+-----+----------------+-------+-------+----------------+-------+----------------+-------+-----+\nonly showing top 1 row\n\n", 
                    "output_type": "stream", 
                    "name": "stdout"
                }
            ], 
            "execution_count": 2, 
            "source": "val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n\nval dfTelco = sqlContext.\n    read.\n    format(\"com.databricks.spark.csv\").\n    option(\"header\", \"true\").\n    option(\"inferschema\", \"true\").\n    load(\"telco.csv\")\n\ndfTelco.show(1)"
        }, 
        {
            "metadata": {}, 
            "cell_type": "code", 
            "outputs": [
                {
                    "text": "root\n |-- region: integer (nullable = true)\n |-- tenure: integer (nullable = true)\n |-- age: integer (nullable = true)\n |-- marital: integer (nullable = true)\n |-- address: integer (nullable = true)\n |-- income: integer (nullable = true)\n |-- ed: integer (nullable = true)\n |-- employ: integer (nullable = true)\n |-- retire: integer (nullable = true)\n |-- gender: integer (nullable = true)\n |-- reside: integer (nullable = true)\n |-- tollfree: integer (nullable = true)\n |-- equip: integer (nullable = true)\n |-- callcard: integer (nullable = true)\n |-- wireless: integer (nullable = true)\n |-- longmon: double (nullable = true)\n |-- tollmon: double (nullable = true)\n |-- equipmon: double (nullable = true)\n |-- cardmon: double (nullable = true)\n |-- wiremon: double (nullable = true)\n |-- longten: double (nullable = true)\n |-- tollten: double (nullable = true)\n |-- equipten: double (nullable = true)\n |-- cardten: double (nullable = true)\n |-- wireten: double (nullable = true)\n |-- multline: integer (nullable = true)\n |-- voice: integer (nullable = true)\n |-- pager: integer (nullable = true)\n |-- internet: integer (nullable = true)\n |-- callid: integer (nullable = true)\n |-- callwait: integer (nullable = true)\n |-- forward: integer (nullable = true)\n |-- confer: integer (nullable = true)\n |-- ebill: integer (nullable = true)\n |-- loglong: double (nullable = true)\n |-- logtoll: string (nullable = true)\n |-- logequi: string (nullable = true)\n |-- logcard: string (nullable = true)\n |-- logwire: string (nullable = true)\n |-- lninc: double (nullable = true)\n |-- custcat: integer (nullable = true)\n |-- churn: integer (nullable = true)\n\n", 
                    "output_type": "stream", 
                    "name": "stdout"
                }
            ], 
            "execution_count": 3, 
            "source": "dfTelco.printSchema"
        }, 
        {
            "metadata": {}, 
            "cell_type": "code", 
            "outputs": [
                {
                    "text": "[Stage 6:=============================>                             (1 + 1) / 2]", 
                    "output_type": "stream", 
                    "name": "stdout"
                }
            ], 
            "execution_count": 4, 
            "source": "val dfTelcoFeb = sqlContext.\n    read.\n    format(\"com.databricks.spark.csv\").\n    option(\"header\", \"true\").\n    option(\"inferschema\", \"true\").\n    load(\"telco_Feb.csv\")"
        }, 
        {
            "metadata": {}, 
            "cell_type": "code", 
            "outputs": [
                {
                    "text": "[Stage 24:=============================>                            (1 + 1) / 2]", 
                    "output_type": "stream", 
                    "name": "stdout"
                }
            ], 
            "execution_count": 5, 
            "source": "import com.ibm.spss.ml.classificationandregression.ensemble.RandomTrees\nimport com.ibm.spss.ml.utils.DataFrameImplicits.DataFrameEnrichImplicitsClass\n\nval ordinal = Array(\"ed\")\nval nominal = Array(\"region\",\n     \"marital\",\n     \"retire\",\n     \"gender\",\n     \"tollfree\",\n     \"equip\",\n     \"callcard\",\n     \"wireless\",\"multline\",\n     \"voice\",\"pager\",\"internet\",\"callid\",\"callwait\",\"forward\",\"confer\",\n     \"ebill\",\n     \"custcat\",\n     \"churn\"\n   )\nval srf = RandomTrees().setTargetField(\"churn\").setNumTrees(10)\nval srfModel = srf.fit(dfTelco.setNominalMeasure(nominal,true).setOrdinalMeasure(ordinal,true))"
        }, 
        {
            "metadata": {}, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": 6, 
            "source": "val predResult = srfModel.transform(dfTelcoFeb)\nval predResultNew = predResult.withColumn(\"prediction\", predResult(\"prediction\").cast(\"double\")).\n    withColumn(\"churn\", predResult(\"churn\").cast(\"double\"))"
        }, 
        {
            "metadata": {}, 
            "cell_type": "code", 
            "outputs": [
                {
                    "text": "acc_result:0.942\n", 
                    "output_type": "stream", 
                    "name": "stdout"
                }
            ], 
            "execution_count": 7, 
            "source": "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\nval evaluator = new MulticlassClassificationEvaluator().setLabelCol(\"churn\").setMetricName(\"accuracy\")\nval acc_result = evaluator.evaluate(predResultNew)\nprintln(s\"acc_result:$acc_result\")"
        }, 
        {
            "metadata": {}, 
            "cell_type": "code", 
            "outputs": [
                {
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 9, 
                    "data": {
                        "text/plain": "Name: Compile Error\nMessage: <console>:55: error: not found: value pc\n       kernel.magics.html(ModelViewer.toHTML(pc,srfModel))\n                                             ^\nStackTrace: "
                    }
                }
            ], 
            "execution_count": 9, 
            "source": "import com.ibm.spss.scala.ModelViewer\nkernel.magics.html(ModelViewer.toHTML(pc,srfModel))"
        }, 
        {
            "metadata": {}, 
            "cell_type": "code", 
            "outputs": [
                {
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 10, 
                    "data": {
                        "text/plain": "$anon$1@379ddb89"
                    }
                }
            ], 
            "execution_count": 10, 
            "source": "import java.io.{File, PrintWriter}\n\nsrfModel.toPMML(\"randomTrees_pmml.xml\")\nval statXML = srfModel.statXML()\nnew PrintWriter(\"StatXML.xml\") {\n      write(statXML)\n      close\n}"
        }, 
        {
            "metadata": {}, 
            "cell_type": "code", 
            "outputs": [], 
            "execution_count": null, 
            "source": ""
        }
    ], 
    "nbformat_minor": 1, 
    "nbformat": 4
}